{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demand Forecasting Example Using Limited Data (14 Months) with CastBoost\n",
    "\n",
    "\n",
    "This notebook presents a demand forecasting approach based on just 14 months of historical data. The goal is to predict demand 28 days ahead using model: CastBoost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "# Mostrar todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# (Opcional) Tambi√©n puedes querer ver todas las filas:\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Y ampliar el ancho del contenido si tienes columnas largas\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', None)  # Para no truncar texto largo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "# --- 1. Data Loading and Initial Preprocessing ---\n",
    "\n",
    "# Load the reservations dataset\n",
    "reservations_df = pd.read_csv('reservations_mod.csv')\n",
    "reservations_df.drop(['reservation_id', 'category_id'], axis=1, inplace=True)\n",
    "\n",
    "# Identify confirmed vs. cancelled reservations\n",
    "# Convert cancellation_date to boolean.\n",
    "reservations_df['is_cancelled'] = reservations_df['cancellation_date'].notna()\n",
    "reservations_df['checkin_date_'] = reservations_df['checkin_date']\n",
    "\n",
    "reservations_df.set_index('checkin_date', inplace=True)\n",
    "reservations_df.sort_index(inplace=True)\n",
    "\n",
    "reservations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert specified columns to datetime objects for easier date manipulation\n",
    "date_columns = ['checkin_date_', 'checkout_date', 'reservation_date', 'cancellation_date']\n",
    "for col in date_columns:\n",
    "    reservations_df[col] = pd.to_datetime(reservations_df[col])\n",
    "\n",
    "# Create a new 'room_type' feature by combining category-related features as strings\n",
    "# This forms a unique identifier for each room type based on its capacity, number of bedrooms, and bathrooms\n",
    "reservations_df['room_type'] = reservations_df['category_capacity'].astype(str) + '_' + \\\n",
    "                               reservations_df['category_bedrooms'].astype(str) + '_' + \\\n",
    "                               reservations_df['category_bathrooms'].astype(str)\n",
    "\n",
    "# Encode the combined 'room_type' string into numerical labels using a label encoder (le)\n",
    "reservations_df['room_type'] = le.fit_transform(reservations_df['room_type'])\n",
    "\n",
    "# Calculate and print the number of unique room types in the dataset\n",
    "room_type = len(reservations_df['room_type'].unique())\n",
    "print(f'Number of room types: {room_type}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features derived from the 'checkin_date_' column for time-based analysis\n",
    "\n",
    "# Calculate the duration of each stay in days by subtracting check-in from check-out\n",
    "reservations_df['duration_of_stay'] = (reservations_df['checkout_date'] - reservations_df['checkin_date_']).dt.days\n",
    "\n",
    "# Extract the day of the week (0=Monday to 6=Sunday) and add 1 to make it 1-based (1=Monday)\n",
    "reservations_df['checkin_day_of_week'] = reservations_df['checkin_date_'].dt.dayofweek + 1\n",
    "\n",
    "# Extract the month (1 to 12) from the check-in date\n",
    "reservations_df['checkin_month'] = reservations_df['checkin_date_'].dt.month\n",
    "\n",
    "# Extract the ISO week number of the year from the check-in date\n",
    "reservations_df['checkin_week_of_year'] = reservations_df['checkin_date_'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# Extract the day of the month (1 to 31) from the check-in date\n",
    "reservations_df['checkin_day_of_the_month'] = reservations_df['checkin_date_'].dt.day\n",
    "\n",
    "# Extract the year from the check-in date\n",
    "reservations_df['checkin_year'] = reservations_df['checkin_date_'].dt.year\n",
    "\n",
    "# Calculate \"lead time\": the number of days between reservation date and check-in date\n",
    "# Missing values are filled with 0\n",
    "reservations_df['lead_time'] = (reservations_df['checkin_date_'] - reservations_df['reservation_date']).dt.days.fillna(0)\n",
    "\n",
    "# Ensure that lead_time is not negative (e.g., if reservation date is after check-in date)\n",
    "reservations_df['lead_time'] = reservations_df['lead_time'].apply(lambda x: max(0, x))\n",
    "\n",
    "# Display the first 10 records for reservations made in the city of M√°laga\n",
    "reservations_df[reservations_df['city'] == 'M√°laga'].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(\n",
    "    reservations_df,\n",
    "    x='lead_time',\n",
    "    nbins=200,  # ajusta la cantidad de bins seg√∫n tu rango de valores\n",
    "    title='Distribuci√≥n del tiempo en d√≠as entre reserva y checkin',\n",
    "    labels={'lead_time': 'Tiempo de espera'},\n",
    "    color_discrete_sequence=['royalblue']\n",
    ")\n",
    "\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Insights\n",
    "\n",
    "### Heavily Right-Skewed Distribution\n",
    "- The majority of reservations occur with short lead times (between 0 and ~20 days).\n",
    "- There's a sharp drop-off in frequency as lead time increases.\n",
    "\n",
    "### Most Common Lead Times\n",
    "- The peak occurs at **0‚Äì5 days**, indicating many guests book very close to their check-in date (possibly last-minute bookings).\n",
    "- A significant tail extends up to **over 300 days**, but very few bookings are made that far in advance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target variable: number of reservations (demand) per check-in date, city, and room type\n",
    "\n",
    "# Group the reservations by 'checkin_date_', 'city', and 'room_type'\n",
    "# Then sum the 'category_capacity' to represent total demand (e.g., number of rooms) for each group\n",
    "df_demand_day = reservations_df.groupby(['checkin_date_', 'city', 'room_type'])['room_type'].size().reset_index(name='demand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el gr√°fico de l√≠neas\n",
    "fig = px.line(df_demand_day, x='checkin_date_', y='demand',\n",
    "              title='Variabilidad diaria de la demanda (n√∫mero de habitaciones)',\n",
    "              color='room_type',\n",
    "              facet_row='city',\n",
    "              labels={'checkin_date_': 'date de check-in'},\n",
    "              markers=True)\n",
    "\n",
    "fig.update_layout(xaxis_title='date', yaxis_title='N√∫mero de habs.', template='plotly_white')\n",
    "\n",
    "# Mostrar el gr√°fico\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target variable: number of reservations (demand) per month, city, and room type\n",
    "\n",
    "# Group the data by year, month, city, and room type\n",
    "# Sum the 'category_capacity' to represent total demand for each group\n",
    "df_demand_month = reservations_df.groupby(['checkin_year', 'checkin_month', 'city', 'room_type'])['room_type'].size().reset_index(name='demand')\n",
    "\n",
    "# Create a new datetime column 'month_year' from 'checkin_month' and 'checkin_year'\n",
    "# This will help in plotting or sorting by calendar date\n",
    "df_demand_month['checkin_month_year'] = pd.to_datetime(df_demand_month['checkin_month'].astype(str) + '-' + df_demand_month['checkin_year'].astype(str))\n",
    "\n",
    "# Display the first 5 rows of the resulting DataFrame\n",
    "df_demand_month.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el gr√°fico de l√≠neas\n",
    "fig = px.line(df_demand_month, x='checkin_month_year', y='demand',\n",
    "              title='Variabilidad mensual de la demanda (n√∫mero de habitaciones)',\n",
    "              color='room_type',\n",
    "              facet_row='city',\n",
    "              labels={'checkin_date_': 'date de check-in'},\n",
    "              markers=True)\n",
    "\n",
    "fig.update_layout(xaxis_title='date', yaxis_title='N√∫mero de habs.', template='plotly_white')\n",
    "\n",
    "# Mostrar el gr√°fico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations from the Data\n",
    "\n",
    "### M√°laga (Top Plot)\n",
    "- The demand for various room types appears relatively stable for the first three quarters of 2019.\n",
    "- Around **November 2019**, there is a noticeable **convergence and increase in demand** for several room types.\n",
    "- **Room_type 0** (blue line) generally shows the **highest demand** throughout most of the year.\n",
    "\n",
    "### Mallorca (Bottom Plot)\n",
    "- The overall demand for rooms is **lower than in M√°laga**.\n",
    "- A distinct **seasonal peak** is observed for **room_type 3** (green line) around **August/September 2019**.\n",
    "- The demand for other room types in Mallorca remains **significantly lower and more stable** throughout the year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the events dataset from a CSV file into a DataFrame\n",
    "events_df = pd.read_csv('events_mod.csv')\n",
    "\n",
    "# Convert the 'start_date' and 'end_date' columns to datetime objects\n",
    "# This allows for proper date-based operations like filtering or sorting\n",
    "events_date_columns = ['start_date', 'end_date']\n",
    "for col in events_date_columns:\n",
    "    events_df[col] = pd.to_datetime(events_df[col])\n",
    "\n",
    "# Create a duplicate of 'start_date' column called 'start_date_'\n",
    "# This might be useful for preserving the original date after setting it as the index\n",
    "events_df['start_date_'] = events_df['start_date']\n",
    "\n",
    "# Set 'start_date' as the DataFrame index for time series operations\n",
    "events_df.set_index('start_date', inplace=True)\n",
    "\n",
    "# Sort the DataFrame by the new datetime index\n",
    "events_df.sort_index(inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "events_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the reservations and events datasets\n",
    "# Match records where the check-in date and city correspond to the event's start date and event city\n",
    "# Use a left join to keep all reservations, even if no matching event is found\n",
    "df_reservation_events = pd.merge(\n",
    "    reservations_df,\n",
    "    events_df,\n",
    "    left_on=['checkin_date_', 'city'],\n",
    "    right_on=['start_date', 'event_city'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# One-hot encode the categorical variables: 'event_type', 'event_city', and 'is_cancelled'\n",
    "# Convert them into binary indicator columns (0 or 1)\n",
    "df_encoded = pd.get_dummies(df_reservation_events, columns=['event_type', 'event_city', 'is_cancelled'], dtype=int)\n",
    "\n",
    "# Encode the original 'city' column using label encoding (transforming cities into integer labels)\n",
    "df_encoded['city'] = le.fit_transform(df_reservation_events['city'])\n",
    "\n",
    "# Compute the correlation matrix for all numerical columns in the encoded DataFrame\n",
    "matriz_correlacion = df_encoded[df_encoded.columns].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt # Para mostrar el gr√°fico\n",
    "# Se ha aumentado el tama√±o de la figura para que sea m√°s grande (antes era 10, 8)\n",
    "plt.figure(figsize=(22, 20))\n",
    "\n",
    "sns.heatmap(matriz_correlacion, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5,\n",
    "            cbar_kws={'label': 'Coeficiente de Correlaci√≥n'})\n",
    "\n",
    "# A√±adir un t√≠tulo al heatmap\n",
    "plt.title('Heatmap de la Matriz de Correlaci√≥n', fontsize=16)\n",
    "\n",
    "# Asegurar que las etiquetas no se corten\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout() # Ajusta el dise√±o para que todo quepa\n",
    "\n",
    "# Mostrar el gr√°fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Heatmap of the Correlation Matrix\n",
    "\n",
    "This heatmap titled **\"Heatmap de la Matriz de Correlaci√≥n\"** visually represents the statistical correlation between multiple variables in the dataset, helping identify relationships between booking behavior, room characteristics, event details, and cancellations.\n",
    "\n",
    "### üß† Notable Observations:\n",
    "\n",
    "- **Booking Dates**:\n",
    "  - Strong positive correlation (**0.97**) between `reservation_date` and `checkin_date` ‚Äî bookings are often made close to the check-in day.\n",
    "\n",
    "- **Event‚ÄìCity Relationship**:\n",
    "  - A **moderate positive correlation (0.63 & 0.35)** between `event_city_M√°laga` and `event_type_festival` (concert and fair) ‚Äî indicating festivals are more common in M√°laga.\n",
    "  - A **low positive correlation (0.13 & 0.10)** between `event_city_Mallorca` and `event_type_national_holiday` and `event_type_sports`.\n",
    "\n",
    "\n",
    "- **Room Characteristics**:\n",
    "  - `category_capacity` and `category_bedrooms` show a **moderate positive correlation (0.41)** ‚Äî larger rooms tend to have more bedrooms.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Conclusion:\n",
    "This correlation matrix helps uncover patterns between booking behaviors, room types, and events ‚Äî essential for understanding cancellation trends, planning inventory, or enhancing forecasting models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the 'city' column and store it as 'city_'\n",
    "# This preserves the original city labels before one-hot encoding\n",
    "df_reservation_events['city_'] = df_reservation_events['city'].copy()\n",
    "\n",
    "# One-hot encode the 'is_cancelled' and 'city' columns\n",
    "# This converts each unique category into its own binary column (0 or 1)\n",
    "df_reservation_events = pd.get_dummies(df_reservation_events, columns=['is_cancelled', 'city'], dtype=int)\n",
    "\n",
    "# Group the dataset to calculate demand\n",
    "# Group by check-in date, room type, and original city (city_)\n",
    "# Count the number of records (reservations) per group to represent demand\n",
    "df_demand = df_reservation_events.groupby(['checkin_date_', 'room_type', 'city_'])['room_type'].size().reset_index(name='demand')\n",
    "\n",
    "# Display the resulting demand DataFrame\n",
    "df_demand.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the event_type column to create binary indicators for each type of event\n",
    "df_events_agg = pd.get_dummies(df_reservation_events, columns=['event_type'], dtype=int)\n",
    "\n",
    "# Extract only the one-hot encoded event columns\n",
    "event_cols = [col for col in df_events_agg.columns if 'event_type_' in col]\n",
    "\n",
    "# Define the keys by which we want to group event data\n",
    "grouping_keys = ['checkin_date_', 'room_type', 'city_']\n",
    "\n",
    "# Aggregate event data at the level of (checkin_date_, room_type, city_)\n",
    "# Summing the one-hot encoded columns counts how many events of each type occurred for that date/room/city combo\n",
    "df_events_summary = df_events_agg.groupby(grouping_keys)[event_cols].sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the model dataset with the demand DataFrame (already at correct granularity)\n",
    "df_model = df_demand.copy()\n",
    "\n",
    "# Aggregate numeric reservation-level features to match the daily granularity\n",
    "# Average duration of stay, lead time, and max event relevance (since multiple events may exist on one day)\n",
    "agg_features = df_reservation_events.groupby(['checkin_date_', 'room_type', 'city_']).agg(\n",
    "    avg_duration_of_stay=('duration_of_stay', 'max'),\n",
    "    avg_lead_time=('lead_time', 'max'),\n",
    "    max_event_relevance=('event_relevance', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Merge aggregated reservation stats\n",
    "df_model = df_model.merge(agg_features, on=['checkin_date_', 'room_type', 'city_'], how='left')\n",
    "\n",
    "# Merge the aggregated event data\n",
    "df_model = df_model.merge(df_events_summary, on=['checkin_date_', 'room_type', 'city_'], how='left')\n",
    "\n",
    "# Add calendar/time features based on the check-in date\n",
    "df_model['checkin_day_of_week'] = df_model['checkin_date_'].dt.dayofweek + 1\n",
    "df_model['checkin_month'] = df_model['checkin_date_'].dt.month\n",
    "df_model['checkin_week_of_year'] = df_model['checkin_date_'].dt.isocalendar().week.astype(int)\n",
    "df_model['checkin_day_of_the_month'] = df_model['checkin_date_'].dt.day\n",
    "df_model['checkin_year'] = df_model['checkin_date_'].dt.year\n",
    "\n",
    "# Convert 'city_' to categorical dummy variables for modeling\n",
    "df_model['city_'] = df_model['city_'].astype(str)\n",
    "df_model = pd.get_dummies(df_model, columns=['city_'], prefix='city', dtype=int)\n",
    "\n",
    "# Fill missing event relevance (NaN ‚Üí 0) for rows with no events\n",
    "df_model['max_event_relevance'] = df_model['max_event_relevance'].fillna(0)\n",
    "\n",
    "# Sort for consistent time-series logic\n",
    "df_model = df_model.sort_values(by=['checkin_date_', 'city_M√°laga', 'city_Mallorca', 'room_type'])\n",
    "\n",
    "# Lag features for avg_duration_of_stay and avg_lead_time by 28 days\n",
    "df_model['avg_duration_of_stay'] = df_model.groupby(['city_M√°laga', 'city_Mallorca', 'room_type'])['avg_duration_of_stay'].shift(28)\n",
    "df_model['avg_lead_time'] = df_model.groupby(['city_M√°laga', 'city_Mallorca', 'room_type'])['avg_lead_time'].shift(28)\n",
    "\n",
    "# Lag features: shift demand backward by 28 days \n",
    "df_model['demand_lag_28'] = df_model.groupby(['city_M√°laga', 'city_Mallorca', 'room_type'])['demand'].shift(28)\n",
    "df_model['demand_lag_35'] = df_model.groupby(['city_M√°laga', 'city_Mallorca', 'room_type'])['demand'].shift(35)\n",
    "df_model['demand_lag_42'] = df_model.groupby(['city_M√°laga', 'city_Mallorca', 'room_type'])['demand'].shift(42)\n",
    "df_model['demand_lag_49'] = df_model.groupby(['city_M√°laga', 'city_Mallorca', 'room_type'])['demand'].shift(49)\n",
    "\n",
    "grouping_keys = ['city_M√°laga', 'city_Mallorca', 'room_type']\n",
    "lag_days = 28\n",
    "window_sizes = [2, 3, 4, 5, 6, 7, 14, 21]\n",
    "rolling_functions = {\n",
    "    'max': 'max',\n",
    "    'min': 'min',\n",
    "    'mean': 'mean',\n",
    "    'std': 'std',\n",
    "    'median': 'median',\n",
    "    'sum': 'sum',\n",
    "    'skew': 'skew',\n",
    "    'kurtosis': 'kurt',\n",
    "    'count': 'count',\n",
    "    'sem': 'sem'\n",
    "}\n",
    "\n",
    "# Calcular las caracter√≠sticas de las ventanas m√≥viles\n",
    "for func_name, func_method in rolling_functions.items():\n",
    "    for window in window_sizes:\n",
    "        column_name = f'demand_rolling_{func_name}_{window}_28'\n",
    "        df_model[column_name] = df_model.groupby(grouping_keys)['demand'].shift(lag_days).rolling(window=window, min_periods=1).agg(func_method)\n",
    "\n",
    "\n",
    "for window in window_sizes:\n",
    "    mean_col = f'demand_rolling_mean_{window}_{lag_days}'\n",
    "    std_col = f'demand_rolling_std_{window}_{lag_days}'\n",
    "    z_col = f'demand_rolling_zscore_{window}_{lag_days}'\n",
    "\n",
    "    df_model[z_col] = (\n",
    "        (df_model['demand'].shift(lag_days) - df_model[mean_col]) / df_model[std_col]\n",
    "    )\n",
    "\n",
    "\n",
    "print(df_model.groupby('room_type')['demand'].describe())\n",
    "\n",
    "df_model['weekend'] = [1 if dia == 6 or dia == 7 else 0 for dia in df_model['checkin_day_of_week']]\n",
    "df_model = pd.get_dummies(df_model, columns=['room_type'], dtype=int)\n",
    "df_model.drop(['checkin_year','event_type_local_holiday'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Fill any remaining NaNs (from lags/rolls) with 0\n",
    "df_model.fillna(0, inplace=True)\n",
    "\n",
    "# Preview the first 10 rows\n",
    "df_model.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for CastBoost\n",
    "\n",
    "# Target variable: 'demand' ‚Äî the number of reservations\n",
    "y = df_model['demand']\n",
    "\n",
    "# Feature set: start with all columns in df_model\n",
    "X = df_model\n",
    "\n",
    "# Define cut-off date to separate train and test sets\n",
    "cut_off_date = pd.to_datetime('2020-01-01')\n",
    "starting_date = pd.to_datetime('2019-01-28')\n",
    "\n",
    "\n",
    "X_train = X[(df_model['checkin_date_'] <= cut_off_date) & (df_model['checkin_date_'] > starting_date)]\n",
    "y_train = y[(df_model['checkin_date_'] <= cut_off_date) & (df_model['checkin_date_'] > starting_date)]\n",
    "\n",
    "X_test = X[df_model['checkin_date_'] > cut_off_date]\n",
    "y_test = y[df_model['checkin_date_'] > cut_off_date]\n",
    "\n",
    "\n",
    "# Drop Columns That Shouldn't Be in the Model\n",
    "X_train = X_train.drop(columns=['demand', 'checkin_date_'])\n",
    "X_test = X_test.drop(columns=['demand', 'checkin_date_'])\n",
    "\n",
    "\n",
    "print(\"Shape de X_train:\", X_train.shape)\n",
    "print(\"Shape de X_test:\", X_test.shape)\n",
    "print(\"Columnas de X:\", X_train.columns.tolist())\n",
    "\n",
    "# # Add missing columns to test set with value 0\n",
    "# missing_cols_in_test = set(X_train.columns) - set(X_test.columns)\n",
    "# for c in missing_cols_in_test:\n",
    "#     X_test[c] = 0\n",
    "\n",
    "# # Ensure test columns match train columns (same order)\n",
    "# X_test = X_test[X_train.columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from catboost import CatBoostRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# # 1. Definir la rejilla de hiperpar√°metros para CatBoost\n",
    "# param_grid = {\n",
    "#     'iterations': [150, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'depth': [5, 6, 7, 8],\n",
    "#     'subsample': [0.6, 0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# # 2. Instanciar el modelo base de CatBoost\n",
    "# cat_model = CatBoostRegressor(\n",
    "#     loss_function='RMSE',\n",
    "#     random_seed=42,\n",
    "#     verbose=0  # Silencia la salida durante GridSearchCV\n",
    "# )\n",
    "\n",
    "# # 3. Configurar GridSearchCV\n",
    "# grid_search = GridSearchCV(\n",
    "#     estimator=cat_model,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=3,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# # 4. Ejecutar la b√∫squeda\n",
    "# print(\"Iniciando GridSearchCV con CatBoost...\")\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # 5. Resultados del mejor modelo\n",
    "# print(\"\\nMejores par√°metros encontrados:\")\n",
    "# print(grid_search.best_params_)\n",
    "# print(f\"\\nMejor RMSE (en validaci√≥n cruzada): {-grid_search.best_score_:.2f}\")\n",
    "\n",
    "# # 6. Evaluar en el conjunto de prueba\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "# # 7. M√©tricas finales\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"\\nResultados del mejor modelo en el conjunto de prueba:\")\n",
    "# print(f\"RMSE: {rmse:.2f}\")\n",
    "# print(f\"R-squared: {r2:.2f}\")\n",
    "\n",
    "# # 8. Importancia de variables\n",
    "# print(\"\\nImportancia de las caracter√≠sticas del mejor modelo:\")\n",
    "# feature_importances = pd.DataFrame({\n",
    "#     'feature': X_train.columns,\n",
    "#     'importance': best_model.get_feature_importance()\n",
    "# }).sort_values(by='importance', ascending=False)\n",
    "# print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CastBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Why Choose CastBoost for Time Series Forecasting\n",
    "\n",
    "### üß© Handling Complex Regressors and Interactions\n",
    "CastBoost effectively handles multiple variables (such as city, room type, events) and captures **non-linear interactions** between them.  \n",
    "> *Example: The impact of an event can vary depending on the city or room type.*\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Robustness to Non-Linear Relationships\n",
    "It can model complex data patterns beyond the basic **linear or additive trends** that models like Prophet are limited to.\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è Feature Engineering Flexibility\n",
    "CastBoost allows the easy integration of **manually crafted features**, such as:\n",
    "- **Lagged variables** (previous demand)\n",
    "- **Rolling windows**\n",
    "- **Date and time breakdowns** (weekday, month, etc.)  \n",
    "These features are highly effective in time series tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### üö® Robustness to Outliers\n",
    "Tree-based models like CastBoost are less sensitive to outliers in the input data ‚Äî  \n",
    "> Useful when there are unusual peaks in bookings or demand.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö° Performance & Scalability\n",
    "CastBoost is known for its **training efficiency and speed**, even with large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### üèÜ Proven High Accuracy\n",
    "It has demonstrated excellent results in **industry use-cases** and **machine learning competitions**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Summary\n",
    "\n",
    "> **I choose CastBoost when I need higher accuracy, the ability to capture complex and non-linear relationships, and I'm ready to invest in advanced feature engineering that goes beyond basic time-series decomposition.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Crear y entrenar el modelo CatBoost\n",
    "cat_model = CatBoostRegressor(\n",
    "    iterations=150,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    loss_function='RMSE',\n",
    "    random_seed=42,\n",
    "    verbose=0  # Cambia a verbose=100 si quieres ver el entrenamiento en consola\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de test\n",
    "y_pred = cat_model.predict(X_test)\n",
    "\n",
    "# Aplicar los factores correctivos por room_type como antes\n",
    "room_type_cols = [col for col in X_test.columns if col.startswith('room_type_')]\n",
    "room_types = np.argmax(X_test[room_type_cols].values, axis=1)\n",
    "\n",
    "correction_factors = {\n",
    "    0: 1.15,\n",
    "    1: 1.2,\n",
    "    2: 1.05,\n",
    "    3: 1.1,\n",
    "    4: 1.05\n",
    "}\n",
    "\n",
    "y_pred = np.array([y_pred[i] * correction_factors[room_type] for i, room_type in enumerate(room_types)])\n",
    "\n",
    "# Evaluar desempe√±o\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "\n",
    "# Importancia de variables\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': cat_model.get_feature_importance()\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importances)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(cat_model, 'modelo_demanda_catboost.joblib')\n",
    "print(\"\\nModel saved successfully as 'modelo_demanda_catboost.joblib'!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Model Evaluation & Feature Importance (CastBoost)\n",
    "\n",
    "### ‚úÖ Model Performance\n",
    "\n",
    "- **RMSE (Root Mean Squared Error):** `4.83`  \n",
    "  This means that, on average, the model's predictions are off by around **4 room bookings** per data point. Lower is better.\n",
    "\n",
    "- **R-squared (R¬≤):** `0.63`  \n",
    "  This indicates that the model explains **62% of the variance** in the demand data. A value close to 1.0 implies good predictive power.\n",
    "\n",
    "> üî∏ **Temporal features**, especially rolling statistics and recent demand lags, are highly predictive of future demand.  \n",
    "> üî∏ **City-specific** binary indicators (`city_M√°laga`, `city_Mallorca`) are also influential.  \n",
    "> üî∏ **Event-related features** (e.g., holidays, festivals, conferences) significantly affect demand.\n",
    "\n",
    "---\n",
    "\n",
    "### üíæ Model Saved\n",
    "\n",
    "- The trained CastBoost model has been successfully saved as:  \n",
    "  **`modelo_demanda_catboost.joblib`**\n",
    "\n",
    "This model is now ready for:\n",
    "- Forecasting future demand\n",
    "- Deployment in a demand estimation pipeline\n",
    "- Further experimentation or hyperparameter tuning\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Asumo que 'y_test' y 'y_pred' ya existen en tu entorno\n",
    "# y est√°n correctamente alineados.\n",
    "\n",
    "# Crear el DataFrame con los resultados\n",
    "results = pd.DataFrame({'actual': y_test, 'predicted': y_pred})\n",
    "results['residual'] = results['actual'] - results['predicted']\n",
    "\n",
    "# Crear el gr√°fico de dispersi√≥n interactivo con Plotly Express\n",
    "fig = px.scatter(\n",
    "    results, \n",
    "    x='actual', \n",
    "    y='residual',\n",
    "    title='An√°lisis de Residuos (Plotly)',\n",
    "    labels={\n",
    "        'actual': 'Demanda Real',\n",
    "        'residual': 'Residuo (Real - Predicho)'\n",
    "    },\n",
    "    template='plotly_white', # Usamos una plantilla limpia\n",
    "    trendline='ols', # A√±ade una l√≠nea de tendencia para ver si hay patrones\n",
    "    trendline_color_override='lightgray'\n",
    ")\n",
    "\n",
    "# A√±adir la l√≠nea horizontal en y=0 para marcar el error cero\n",
    "fig.add_hline(\n",
    "    y=0, \n",
    "    line_dash=\"dash\", \n",
    "    line_color=\"red\",\n",
    "    annotation_text=\"Error Cero\", \n",
    "    annotation_position=\"bottom right\"\n",
    ")\n",
    "\n",
    "# Ajustar el tama√±o de la figura\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "\n",
    "# Mostrar el gr√°fico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìâ Residual Plot Interpretation\n",
    "\n",
    "This plot shows the error of your model (**Residual = Actual Demand - Prediction**) as a function of the actual demand value.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Main Observation: **Heteroscedasticity (Cone Shape)**\n",
    "\n",
    "- **What you see**: The residuals are not randomly scattered around the red \"Zero Error\" line. Instead, they form a cone that opens to the right.\n",
    "- **What it means**: The model‚Äôs error increases as actual demand increases.  \n",
    "  - For **low demand values** (e.g., below 15), the model performs quite well ‚Äî errors are small and tightly clustered.\n",
    "  - For **high demand values** (e.g., above 30), the errors become much larger and more unpredictable.\n",
    "  - This indicates the model struggles significantly to predict **demand spikes**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Secondary Observation: **Model Bias (Gray Trend Line)**\n",
    "\n",
    "- **What you see**: The light gray trend line of the residuals has a **positive slope**.\n",
    "- **What it means**: This shows **systematic bias** in the model.  \n",
    "  - The model tends to **underestimate demand**, and this underestimation worsens as actual demand increases.\n",
    "  - As a result, most large errors are **positive** (Actual > Prediction).\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Conclusion & Next Steps\n",
    "\n",
    "The diagnosis is clear:  \n",
    "Your model lacks the predictive power to accurately capture **high-demand days**, leading to consistent underestimation and increasing error for peak scenarios.\n",
    "\n",
    "‚úÖ **Next steps we might consider**:\n",
    "- Engineer features that better capture demand surges (e.g., proximity to holidays, special events, lagged peaks).\n",
    "- Try ensemble models or non-linear architectures.\n",
    "- Train a separate model specialized for high-demand periods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cargar el modelo desde el archivo\n",
    "loaded_model = joblib.load('modelo_demanda_catboost.joblib')\n",
    "print(\"Modelo cargado exitosamente.\")\n",
    "\n",
    "# 2. Realizar predicciones con el modelo cargado\n",
    "prediction = loaded_model.predict(X_test)\n",
    "\n",
    "# 3. Calcular el RMSE para evaluar el desempe√±o\n",
    "rmse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "print(f\"RMSE: {rmse:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
